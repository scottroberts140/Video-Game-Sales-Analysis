{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile Carrier Subscriber Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #007bff; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "# Project Overview\n",
    "\n",
    "This project develops a Machine Learning model to analyze subscriber behavior, and recommend one of the carrier's newer plans: Smart or Ultra.    \n",
    "\n",
    "## Methodology  \n",
    "\n",
    "Code for working with and manipulating datasets and Machine Learning models is contained in several classes and functions. This approach avoids repetitive code, and allows the functionality to be included easily in other projects.\n",
    "\n",
    "* Support Code\n",
    "    * Enums\n",
    "        * MLModel\n",
    "        * MLModelMethod\n",
    "        * MLModelSearch\n",
    "    * Classes for facilitating analysis of the dataset:\n",
    "        * DataframeColumn\n",
    "        * DataframeInfo\n",
    "    * Functions\n",
    "        * is_float_string\n",
    "        * analyze_column_data\n",
    "        * analyze_dataset\n",
    "        * any_to_list\n",
    "    * Classes for working with Machine Learning models:\n",
    "        * MLModelSets\n",
    "        * MLDataset\n",
    "        * MLModelResult\n",
    "        * MLDecisionTree\n",
    "        * MLRandomForest\n",
    "        * MLLogisticRegression\n",
    "        * MLLinearRegression\n",
    "        * MLThreeSetSplit\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #007bff; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "# Environment Setup and Required Libraries\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skopt import gp_minimize  # Gaussian Process optimization\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #007bff; padding: 10px; border-radius: 5px;\">\n",
    "    \n",
    "# Supporting Classes and Functions\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #3F9B0B; padding: 10px; border-radius: 5px;\">\n",
    "    \n",
    "## Enums\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLModel\n",
    "\n",
    "### Summary\n",
    "An enum for specifying a Machine Learning model type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLModel(Enum):\n",
    "    Undefined = 0,\n",
    "    DecisionTree = 1,\n",
    "    RandomForestGrid = 2,\n",
    "    RandomForestRandomized = 3,\n",
    "    RandomForestBayesianOptimization = 4,\n",
    "    LogisticRegression = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLModelMethod\n",
    "\n",
    "### Summary\n",
    "An enum for specifying the method applied in the evaluation of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLModelMethod(Enum):\n",
    "    Undefined = 0,\n",
    "    Accuracy = 1,\n",
    "    RMSE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLModelSearch\n",
    "\n",
    "### Summary\n",
    "An enum for specifying the type of search to use for evaluating model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLModelSearch(Enum):\n",
    "    Undefined = 0,\n",
    "    Grid = 1,\n",
    "    Randomized = 2,\n",
    "    BayesianOptimization = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLModelResultStorageParadigm\n",
    "\n",
    "### Summary\n",
    "An enum for specifying the paradigm for storing model results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLModelStorageParadigm(Enum):\n",
    "    Overwrite = 0,\n",
    "    LowestValue = 1,\n",
    "    HighestValue = 2,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #3F9B0B; padding: 10px; border-radius: 5px;\">\n",
    "    \n",
    "## Functions / Classes\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataframeColumn\n",
    "\n",
    "### Summary\n",
    "Describes a column within a dataframe.\n",
    "\n",
    "### Attributes:\n",
    "* **`data_type`** (`str`): The data type of the column. Read-only.  \n",
    "* **`name`** (`str`): The name of the column. Read-only.  \n",
    "* **`non_null_count`** (`int`): The number of non-null values in the column. Read-only.  \n",
    "\n",
    "#### Constructor (`__init__`)\n",
    "Initializer.\n",
    "\n",
    "##### Arguments:\n",
    "* **`name`** (`str`): The name of the column.  \n",
    "* **`non_null_count`** (`int`): The number of non-null values in the column.   \n",
    "* **`data_type`** (`str`): The data type of the column.   \n",
    "\n",
    "\n",
    "### Public Methods\n",
    "\n",
    "#### `dfc_list_from_df(df)`\n",
    "Static class method to create a list of DataframeColumn objects for the columns in a specified dataframe.\n",
    "\n",
    "##### Arguments:\n",
    "* **`df`** (`dataframe`): The dataframe.  \n",
    "\n",
    "##### Returns:\n",
    "  * `[DataframeColumn]` A list of DataframeColumn objects for the columns in the specified dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataframeColumn:\n",
    "    @staticmethod\n",
    "    def dfc_list_from_df(df):        \n",
    "        df_columns = df.columns.tolist()\n",
    "        df_non_null_count = df.count().tolist()\n",
    "        df_data_types = df.dtypes.tolist()\n",
    "        n = len(df_columns)\n",
    "        dfc_list = []\n",
    "\n",
    "        for c in range(n):\n",
    "            dfc = DataframeColumn(df_columns[c],\n",
    "                                  df_non_null_count[c],\n",
    "                                  df_data_types[c])\n",
    "            dfc_list.append(dfc)\n",
    "        \n",
    "        return dfc_list\n",
    "\n",
    "    def __init__(self, name, non_null_count, data_type):\n",
    "        self._name = name\n",
    "        self._non_null_count = non_null_count\n",
    "        self._data_type = data_type\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "\n",
    "    @property\n",
    "    def non_null_count(self):\n",
    "        return self._non_null_count\n",
    "\n",
    "    @property\n",
    "    def data_type(self):\n",
    "        return self._data_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataframeInfo\n",
    "\n",
    "### Summary\n",
    "Provides a detailed description of a dataframe.\n",
    "\n",
    "### Attributes:\n",
    "* **`columns`** (`[DataframeColumn]`): A list of DataframeColumn objects representing the columns within the dataframe. Read-only.\n",
    "* **`duplicate_row_count`** (`int`): The number of duplicate rows. Read-only.\n",
    "* **`row_count`** (`int`): The number of rows. Read-only.\n",
    "\n",
    "#### Constructor (`__init__`)\n",
    "Initializer.\n",
    "\n",
    "##### Arguments:\n",
    "* **`df`** (`Dataframe`): The dataframe.  \n",
    "\n",
    "### Public Methods\n",
    "\n",
    "#### `info(self)`\n",
    "Prints detailed information describing the dataframe.\n",
    "\n",
    "\n",
    "Sample Output:  \n",
    "\n",
    "```python\n",
    "Rows: 3214  \n",
    "Duplicate rows: 0  \n",
    "\n",
    "Column           Non-null   Data type   \n",
    "calls                3214   float64     \n",
    "minutes              3214   float64     \n",
    "messages             3214   float64     \n",
    "mb_used              3214   float64     \n",
    "\n",
    "Column:             calls\n",
    "Data type:          float64\n",
    "Non-null:           3214\n",
    "N/A count:          0\n",
    "Unique values:      184\n",
    "Integer values:     3214\n",
    "Non-integer values: 0\n",
    "\n",
    "\n",
    "\n",
    "Column:             minutes\n",
    "Data type:          float64\n",
    "Non-null:           3214\n",
    "N/A count:          0\n",
    "Unique values:      3144\n",
    "Integer values:     60\n",
    "Non-integer values: 3154\n",
    "\n",
    "\n",
    "Column:             messages\n",
    "Data type:          float64\n",
    "Non-null:           3214\n",
    "N/A count:          0\n",
    "Unique values:      180\n",
    "Integer values:     3214\n",
    "Non-integer values: 0\n",
    "\n",
    "\n",
    "Column:             mb_used\n",
    "Data type:          float64\n",
    "Non-null:           3214\n",
    "N/A count:          0\n",
    "Unique values:      3203\n",
    "Integer values:     34\n",
    "Non-integer values: 3180\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataframeInfo:\n",
    "    def __init__(self, df):\n",
    "        self._row_count = len(df)\n",
    "        self._duplicate_row_count = df.duplicated().sum()\n",
    "        self._columns = DataframeColumn.dfc_list_from_df(df)\n",
    "\n",
    "    @property\n",
    "    def row_count(self):\n",
    "        return self._row_count\n",
    "\n",
    "    @property\n",
    "    def duplicate_row_count(self):\n",
    "        return self._duplicate_row_count\n",
    "\n",
    "    @property\n",
    "    def columns(self):\n",
    "        return self._columns\n",
    "    \n",
    "    def info(self):\n",
    "        print(f'Rows: {self.row_count}')\n",
    "        print(f'Duplicate rows: {self.duplicate_row_count}')\n",
    "        print()\n",
    "        col_headers = ['Column', 'Non-null', 'Data type']\n",
    "        col_width = [15, 10, 12]\n",
    "        print(\n",
    "            f'{col_headers[0]:<{col_width[0]}}{col_headers[1]:>{col_width[1]}}   {col_headers[2]:<{col_width[2]}}')\n",
    "\n",
    "        for c in self.columns:\n",
    "            print(\n",
    "                f'{c.name:<{col_width[0]}}{c.non_null_count:>{col_width[1]}}   {c.data_type.name:<{col_width[2]}}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `is_float_string(value)`\n",
    "Determines whether a string can be converted to a float.  \n",
    "\n",
    "##### Arguments:\n",
    "* **`value`** (`str`): The string value to test.  \n",
    "\n",
    "##### Returns:\n",
    "* `True, if the string can be converted to a float; otherwise, False.`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float_string(value):\n",
    "    if value is None:\n",
    "        return False\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `analyze_column_data(series, dataframe_column)`\n",
    "Analyzes the data within a column, and prints a summary of the data.\n",
    "\n",
    "##### Arguments:\n",
    "* **`series`** (`Series`): The data contained in the column.  \n",
    "* **`dataframe_column`** (`DataframeColumn`): The corresponding DataframeColumn object.  \n",
    "\n",
    "Sample Output:  \n",
    "\n",
    "```python\n",
    "Column:             calls\n",
    "Data type:          float64\n",
    "Non-null:           3214\n",
    "N/A count:          0\n",
    "Unique values:      184\n",
    "Integer values:     3214\n",
    "Non-integer values: 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_column_data(series, dataframe_column):\n",
    "    series_length = len(series)\n",
    "    is_float_type = (dataframe_column.data_type.name == 'float64')\n",
    "    integer_analysis = ''\n",
    "\n",
    "    if is_float_type:\n",
    "        integer_value_count = series.apply(lambda x: x.is_integer()).sum()\n",
    "        non_integer_value_count = series_length - integer_value_count\n",
    "        integer_analysis = f\"\"\"Integer values:     {integer_value_count}\n",
    "Non-integer values: {non_integer_value_count}\n",
    "\"\"\"\n",
    "\n",
    "    is_object_data_type = (dataframe_column.data_type.name == 'object')\n",
    "    object_analysis = ''\n",
    "\n",
    "    if is_object_data_type:\n",
    "        numeric_value_count = series.str.isnumeric().sum()\n",
    "        non_numeric_value_count = series_length - \\\n",
    "            series.apply(is_float_string).sum()\n",
    "\n",
    "        object_analysis = f\"\"\"Numeric values:     {numeric_value_count}\n",
    "Non-numeric values: {non_numeric_value_count}\n",
    "\"\"\"\n",
    "\n",
    "    analysis = f\"\"\"\n",
    "Column:             {dataframe_column.name}\n",
    "Data type:          {dataframe_column.data_type.name}\n",
    "Non-null:           {dataframe_column.non_null_count}\n",
    "N/A count:          {series.isna().sum()}\n",
    "Unique values:      {series.nunique()}\"\"\"\n",
    "\n",
    "    print(analysis)\n",
    "\n",
    "    if is_float_type:\n",
    "        print(integer_analysis)\n",
    "\n",
    "    if is_object_data_type:\n",
    "        print(object_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `analyze_dataset(df)`\n",
    "Analyzes the data in a dataset, and returns a DataframeInfo object containing the results.\n",
    "\n",
    "##### Arguments:\n",
    "* **`df`** (`dataset`): The dataset to analyze.\n",
    "\n",
    "##### Returns:\n",
    "* `A DataframeInfo object containing the results of the analysis.` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset(df):\n",
    "    df_info = DataframeInfo(df)\n",
    "    df_info.info()\n",
    "\n",
    "    n = len(df_info.columns)\n",
    "\n",
    "    for c in range(n):\n",
    "        col = df_info.columns[c]\n",
    "        analyze_column_data(df[col.name], df_info.columns[c])\n",
    "\n",
    "    return df_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `any_to_list(a)`\n",
    "Returns a list from an input value.\n",
    "\n",
    "##### Arguments:\n",
    "* **`a`** (`any`): The value to convert to a list. See Notes.    \n",
    "\n",
    "##### Returns:\n",
    "* `A list containing the input value.`\n",
    "\n",
    "##### Notes:\n",
    "1. The following data types are supported:  \n",
    "    * list (returns the input value)\n",
    "    * np.ndarray\n",
    "    * int, float, str\n",
    "    * tuple\n",
    "    * dict (a list of the values is returned)\n",
    "\n",
    "&emsp;Any other data type returns an empty list, and a message is printed to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def any_to_list(a):\n",
    "    if isinstance(a, list):\n",
    "        return a\n",
    "    elif isinstance(a, np.ndarray):\n",
    "        return a.tolist()\n",
    "    elif isinstance(a, (int, float, str)):\n",
    "        return [str(a)]\n",
    "    elif isinstance(a, tuple):\n",
    "        return [list(a)]\n",
    "    elif isinstance(a, dict):\n",
    "        return list(a.values())\n",
    "    else:\n",
    "        print(f'Unrecognized data type: {type(a)}')\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLModelSets(ABC)\n",
    "\n",
    "### Summary\n",
    "Abstract class for use with classes that represent source datasets for model training.\n",
    "\n",
    "### Attributes:\n",
    "* **`df_test`** (`dataset`): The test dataset. Read-only.  \n",
    "* **`df_train`** (`dataset`): The training dataset. Read-only.  \n",
    "* **`df_valid`** (`dataset`): The validation dataset. Read-only.  \n",
    "* **`random_state`** (`int`): The random state to use. Read-only.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLModelSets(ABC):\n",
    "    @abstractmethod\n",
    "    def df_train(self):\n",
    "        pass\n",
    "\n",
    "    def df_test(self):\n",
    "        pass\n",
    "\n",
    "    def df_valid(self):\n",
    "        pass\n",
    "\n",
    "    def random_state(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLDataset\n",
    "\n",
    "### Summary\n",
    "Represents an Machine Learning dataset.\n",
    "\n",
    "### Attributes:\n",
    "* **`features`** (`[Series]`): The features in the dataset. Read-only.  \n",
    "* **`target`** (`Series`): The target in the dataset. Read-only.  \n",
    "\n",
    "#### Constructor (`__init__`)\n",
    "Initializer.\n",
    "\n",
    "##### Arguments:\n",
    "* **`features`** (`[Series]`): The features in the dataset.   \n",
    "* **`target`** (`Series`): The target in the dataset.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLDataset:\n",
    "    def __init__(self, features, target):\n",
    "        self._features = features\n",
    "        self._target = np.ravel(target)\n",
    "    \n",
    "    @property\n",
    "    def features(self):\n",
    "        return self._features\n",
    "    \n",
    "    @property\n",
    "    def target(self):\n",
    "        return self._target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLModelResult\n",
    "\n",
    "### Summary\n",
    "Container for results of a model test.\n",
    "\n",
    "### Attributes:\n",
    "* **`model`** (`DecisionTreeRegressor`): The model that corresponds to the score. Read-only.  \n",
    "* **`model_method`** (`MLModelMethod`): The method used for testing. Read-only.\n",
    "* **`parameters`** (`int`): The parameters that correspond to the score. Read-only.\n",
    "* **`score`** (`float`): The score corresponding to the model. Read-only.\n",
    "\n",
    "#### Constructor (`__init__`)\n",
    "Initializer.\n",
    "\n",
    "##### Arguments:\n",
    "* **`model_method`** (`MLModelMethod`): The method used for testing.  \n",
    " \n",
    "### Public Methods:\n",
    "\n",
    "#### `reset(self)`\n",
    "Resets the instance properties to None.\n",
    "\n",
    "#### `store_result(self, model, score, parameters, storage_paradigm)`\n",
    "Stores the result of a model test.\n",
    "\n",
    "##### Arguments:\n",
    "* **`model`** (`any`): The model.  \n",
    "* **`score`** (`float`): The score for the model.\n",
    "* **`parameters`** (`int`): The parameters that generated the score.  \n",
    "* **`storage_paradigm`** (`MLModelStorageParadigm`, *default*= `MLModelStorageParadigm.Overwrite`): The paradigm to use for storing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLModelResult:\n",
    "    def __init__(self,\n",
    "                 model_method\n",
    "                ):\n",
    "        self._model_method = model_method\n",
    "        self.reset()\n",
    "\n",
    "    @property\n",
    "    def model_method(self):\n",
    "        return self._model_method\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "        \n",
    "    @property\n",
    "    def score(self):\n",
    "        return self._score\n",
    "\n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return self._parameters\n",
    "\n",
    "    def reset(self):\n",
    "        self._score = None\n",
    "        self._parameters = None\n",
    "        self._model = None\n",
    "\n",
    "    def store_result(self,\n",
    "                     model,\n",
    "                     score,\n",
    "                     parameters,\n",
    "                     storage_paradigm=MLModelStorageParadigm.Overwrite\n",
    "                    ):\n",
    "        def overwrite_values():\n",
    "                self._model = model\n",
    "                self._score = score\n",
    "                self._parameters = parameters\n",
    "        \n",
    "        match storage_paradigm:\n",
    "            case MLModelStorageParadigm.Overwrite:\n",
    "                overwrite_values()\n",
    "            case MLModelStorageParadigm.HighestValue:\n",
    "                if self._score is None or self._score < score:\n",
    "                    overwrite_values()\n",
    "            case MLModelStorageParadigm.LowestValue:\n",
    "                if self._score is None or self._score > score:\n",
    "                    overwrite_values()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLDecisionTree\n",
    "\n",
    "### Summary\n",
    "Represents a Decision Tree Classifier.\n",
    "\n",
    "### Attributes:\n",
    "* **`accuracy_results`** (`MLModelResult`): The results of the accuracy test with the highest score. Read-only.\n",
    "* **`ml_modelsets`** (`MLModelSets`): The associated model sets object. Internal.\n",
    "* **`rmse_results`** (`MLModelResult`): The results of the rmse test with the highest score. Read-only.\n",
    "\n",
    "#### Constructor (`__init__`)\n",
    "Initializer.\n",
    "\n",
    "##### Arguments:\n",
    "* **`ml_modelsets`** (`MLModelSets`): The associated model sets object.  \n",
    "\n",
    "### Public Methods:\n",
    "\n",
    "#### `tune(self, max_depth, min_samples_split, log)`\n",
    "Determines the best accuracy model for the Decision Tree classifier, and updates the accuracy_results property.\n",
    "\n",
    "##### Arguments:\n",
    "* **`max_depth`** (`[int]`, *default*= `None`): The max depth of the tree.  The calculate_max_depth() method is called on the value passed in this parameter.\n",
    "* **`min_samples_split`** (`[int]`, *default*= `None`): The list of values for the min_samples_split parameter. The calculate_min_samples_split() method is called on the value passed in this parameter.\n",
    "* **`log`** (`bool`, *default*= `True`): If True, results are output to the console.\n",
    "\n",
    "#### `rmse(self, max_depth, log)`\n",
    "Determines the best RMSE model for the Decision Tree classifier, and update the rmse_results property.\n",
    "\n",
    "##### Arguments:\n",
    "* **`max_depth`** (`range`, *default*= `None`): The range of max_depth values.  The calculate_max_depth() method is called on the value passed in this parameter.\n",
    "* **`log`** (`bool`, *default*= `True`): If True, results are output to the console.\n",
    "\n",
    "### Private Methods:\n",
    "\n",
    "#### `_calculate_max_depth(self, proposed_value)`\n",
    "Returns the values for max_depth based on the proposed_value. This method is intended to be used to supply default values for the max_depth parameter of the public methods, if the max_depth parameter is None.\n",
    "\n",
    "##### Arguments:\n",
    "* **`proposed_value`** (`[int]`, *default*= `None`): The max depth of the tree. If proposed_value is None, the value returned is [None, 10, 20].\n",
    "\n",
    "##### Returns:\n",
    "The value to use for the max_depth parameter.\n",
    "\n",
    "#### `_calculate_min_samples_split(self, proposed_value)`\n",
    "Returns the values for min_samples_split based on the proposed_value. This method is intended to be used to supply default values for the min_samples_split parameter of the public methods, if the min_samples_split parameter is None.\n",
    "\n",
    "##### Arguments:\n",
    "* **`proposed_value`** (`[int]`, *default*= `None`): The list of values for the min_samples_split parameter. If proposed_value is None, the value returned is [2, 5, 10].\n",
    "\n",
    "##### Returns:\n",
    "The value to use for the min_samples_split parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLDecisionTree:\n",
    "    def __init__(self, \n",
    "                 ml_modelsets,\n",
    "                ):\n",
    "        self._ml_modelsets = ml_modelsets\n",
    "        self._accuracy_results = MLModelResult(MLModelMethod.Accuracy)\n",
    "        self._rmse_results = MLModelResult(MLModelMethod.RMSE)\n",
    "\n",
    "    @property\n",
    "    def accuracy_results(self):\n",
    "        return self._accuracy_results\n",
    "\n",
    "    @property\n",
    "    def rmse_results(self):\n",
    "        return self._rmse_results\n",
    "    \n",
    "    def _calculate_max_depth(\n",
    "            self,\n",
    "            proposed_value=None\n",
    "    ):\n",
    "        if proposed_value is None:\n",
    "            max_depth = [None, 10, 20]\n",
    "        else:\n",
    "            max_depth = proposed_value\n",
    "\n",
    "        return max_depth\n",
    "    \n",
    "    def _calculate_min_samples_split(\n",
    "            self,\n",
    "            proposed_value=None\n",
    "    ):\n",
    "        if proposed_value is None:\n",
    "            min_samples_split = [2, 5, 10]\n",
    "        else:\n",
    "            min_samples_split = proposed_value\n",
    "        \n",
    "        return min_samples_split\n",
    "\n",
    "    def tune(self,\n",
    "             max_depth=None,\n",
    "             min_samples_split=None,\n",
    "             log=True\n",
    "            ):\n",
    "        self._accuracy_results.reset()\n",
    "\n",
    "        if log:\n",
    "            print()\n",
    "            print(f'------------------ Decision Tree (Accuracy) ------------------')\n",
    "\n",
    "        max_depth = self._calculate_max_depth(max_depth)\n",
    "        min_samples_split = self._calculate_min_samples_split(min_samples_split)\n",
    "\n",
    "        param_grid = {\n",
    "            'max_depth': max_depth,\n",
    "            'min_samples_split': min_samples_split\n",
    "        }\n",
    "\n",
    "        dtree = DecisionTreeClassifier(random_state = self._ml_modelsets.random_state)\n",
    "        grid_search = GridSearchCV(dtree,\n",
    "                                   param_grid,\n",
    "                                   cv=5,\n",
    "                                   scoring='accuracy',\n",
    "                                   n_jobs=-1\n",
    "                                   )\n",
    "        grid_search.fit(self._ml_modelsets.df_train.features, self._ml_modelsets.df_train.target)\n",
    "        self._accuracy_results.store_result(dtree, grid_search.best_score_, grid_search.best_params_)\n",
    "\n",
    "        if log:\n",
    "            print()\n",
    "            print(f'Best parameters: {grid_search.best_params_}')\n",
    "            print(f'Best score: {grid_search.best_score_}')\n",
    "\n",
    "    def rmse(self,\n",
    "             max_depth=None,\n",
    "             log=True\n",
    "            ):\n",
    "        self._rmse_results.reset()\n",
    "        max_depth = self._calculate_max_depth(max_depth)\n",
    "\n",
    "        if log:\n",
    "            print()\n",
    "            print(f'------------------- Decision Tree (RMSE) -------------------')\n",
    "\n",
    "        for depth in max_depth:\n",
    "            model = DecisionTreeClassifier(random_state=self._ml_modelsets.random_state, max_depth=depth)\n",
    "            model.fit(self._ml_modelsets.df_main.features, self._ml_modelsets.df_main.target)\n",
    "            predictions = model.predict(self._ml_modelsets.df_test.features)\n",
    "            rmse = mean_squared_error(self._ml_modelsets.df_test.target, predictions) ** 0.5\n",
    "            self._rmse_results.store_result(model, rmse, depth, storage_paradigm=MLModelStorageParadigm.LowestValue)\n",
    "\n",
    "            if log:\n",
    "                print(f'max_depth = {depth} : {rmse}')\n",
    "\n",
    "        if log:\n",
    "            print()\n",
    "            print(f'Best model: {self._rmse_results.parameters} ({self._rmse_results.score})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLRandomForest\n",
    "\n",
    "### Summary\n",
    "Represents a Random Forest Classifier.\n",
    "\n",
    "### Attributes:\n",
    "* **`accuracy_results`** (`MLModelResult`): The results of the accuracy test with the highest score. Read-only.\n",
    "* **`ml_modelsets`** (`MLModelSets`): The associated model sets object. Internal.\n",
    "* **`model_search`** (`MLModelSets`): The search method to use for evaluating model parameters. Internal.\n",
    "* **`rmse_results`** (`MLModelResult`): The results of the rmse test with the highest score. Read-only.\n",
    "\n",
    "#### Constructor (`__init__`)\n",
    "Initializer.\n",
    "\n",
    "##### Arguments:\n",
    "* **`ml_modelsets`** (`MLModelSets`): The associated model sets object. Internal.  \n",
    "* **`model_search`** (`MLModelSets`): The search method to use for evaluating model parameters. Internal.\n",
    "\n",
    "### Public Methods:\n",
    "\n",
    "#### `calculate_best_model(self, n_estimators, max_depth, min_samples_split, log)`\n",
    "Calculates the best model for the Random Forest Classifier.\n",
    "\n",
    "##### Arguments:\n",
    "* **`n_estimators`** (`range`, *default*= `None`): The range of estimators to use. See Notes.\n",
    "* **`max_depth`** (`[int]`, *default*= `None`): The max depth of the tree.  See Notes.\n",
    "* **`min_samples_split`** (`[int]`, *default*= `None`): The list of values for the min_samples_split parameter. See Notes.\n",
    "* **`log`** (`bool`, *default*= `True`): If True, results are output to the console.\n",
    "\n",
    "##### Notes:\n",
    "1. If n_estimators is None, the value assigned will be based on the model_search attribute:\n",
    "    * Grid: [10, 50, 100, 200]\n",
    "    * Randomized: random.randint(10, 200)\n",
    "    * Bayesian: (100, 500), i.e., (low, high)\n",
    "2. To pass a value for n_estimators, use the following guidelines for the parameter, based on the model_search attribute:\n",
    "    * Grid: pass [int]\n",
    "    * Randomized: int\n",
    "    * Bayesian: (low, high)\n",
    "3. If max_depth is None, the value assigned will be based on the model_search attribute:\n",
    "    * Grid: [None, 10, 20]\n",
    "    * Randomized: [None, 10, 20, 30]\n",
    "    * Bayesian: (2, 20), i.e., (low, high)\n",
    "4. To pass a value for max_depth, use the following guidelines for the parameter, based on the model_search attribute:\n",
    "    * Grid: pass [int]\n",
    "    * Randomized: int\n",
    "    * Bayesian: (low, high)\n",
    "5. If min_samples_split is None, the value assigned will be based on the model_search attribute:\n",
    "    * Grid: [2, 5, 10]\n",
    "    * Randomized: random.randint(2, 11)\n",
    "    * Bayesian: (1e-5, 1e-2), i.e., (low, high)\n",
    "6. To pass a value for min_samples_split, use the following guidelines for the parameter, based on the model_search attribute:\n",
    "    * Grid: pass [int]\n",
    "    * Randomized: int\n",
    "    * Bayesian: (low, high)\n",
    "\n",
    "#### `rmse(self, max_depth, n_estimators)`\n",
    "Determines the best RMSE for the Random Forest Classifier, and updates the rmse_results property.\n",
    "\n",
    "##### Arguments:\n",
    "* **`max_depth`** (`[int]`, *default*= `None`): The max depth of the tree.  See Notes.\n",
    "* **`n_estimators`** (`range`, *default*= `None`): The range of estimators to use. See Notes.\n",
    "* **`log`** (`bool`, *default*= `True`): If True, results are output to the console.\n",
    "\n",
    "##### Notes:\n",
    "1. If max_depth is None, the value assigned will be based on the model_search attribute:\n",
    "    * Grid: [None, 10, 20]\n",
    "    * Randomized: [None, 10, 20, 30]\n",
    "    * Bayesian: (2, 20), i.e., (low, high)\n",
    "2. To pass a value for max_depth, use the following guidelines for the parameter, based on the model_search attribute:\n",
    "    * Grid: pass [int]\n",
    "    * Randomized: int\n",
    "    * Bayesian: (low, high)\n",
    "3. If n_estimators is None, the value assigned will be based on the model_search attribute:\n",
    "    * Grid: [10, 50, 100, 200]\n",
    "    * Randomized: random.randint(10, 200)\n",
    "    * Bayesian: (100, 500), i.e., (low, high)\n",
    "4. To pass a value for n_estimators, use the following guidelines for the parameter, based on the model_search attribute:\n",
    "    * Grid: pass [int]\n",
    "    * Randomized: int\n",
    "    * Bayesian: (low, high)\n",
    "\n",
    "### Private Methods:\n",
    "\n",
    "#### `_calculate_max_depth(self, proposed_value)`\n",
    "Returns the values for max_depth based on the proposed_value. This method is intended to be used to supply default values for the max_depth parameter of the public methods, if the max_depth parameter is None.\n",
    "\n",
    "##### Arguments:\n",
    "* **`proposed_value`** (`[int]`, *default*= `None`): The max depth of the tree.  See Notes.\n",
    "\n",
    "##### Returns:\n",
    "The value to use for the max_depth parameter.\n",
    "\n",
    "##### Notes:\n",
    "1. If max_depth is None, the value assigned will be based on the model_search attribute:\n",
    "    * Grid: [None, 10, 20]\n",
    "    * Randomized: [None, 10, 20, 30]\n",
    "    * Bayesian: (2, 20), i.e., (low, high)\n",
    "2. To pass a value for max_depth, use the following guidelines for the parameter, based on the model_search attribute:\n",
    "    * Grid: pass [int]\n",
    "    * Randomized: int\n",
    "    * Bayesian: (low, high)\n",
    "\n",
    "#### `_calculate_min_samples_split(self, proposed_value)`\n",
    "Returns the values for min_samples_split based on the proposed_value. This method is intended to be used to supply default values for the min_samples_split parameter of the public methods, if the min_samples_split parameter is None.\n",
    "\n",
    "##### Arguments:\n",
    "* **`proposed_value`** (`[int]`, *default*= `None`): The list of values for the min_samples_split parameter. See Notes.\n",
    "\n",
    "##### Returns:\n",
    "The value to use for the min_samples_split parameter.\n",
    "\n",
    "##### Notes:\n",
    "1. If min_samples_split is None, the value assigned will be based on the model_search attribute:\n",
    "    * Grid: [2, 5, 10]\n",
    "    * Randomized: random.randint(2, 11)\n",
    "    * Bayesian: (1e-5, 1e-2), i.e., (low, high)\n",
    "2. To pass a value for min_samples_split, use the following guidelines for the parameter, based on the model_search attribute:\n",
    "    * Grid: pass [int]\n",
    "    * Randomized: int\n",
    "    * Bayesian: (low, high)\n",
    "\n",
    "#### `_calculate_n_estimators(self, proposed_value)`\n",
    "Returns the values for n_estimators based on the proposed_value. This method is intended to be used to supply default values for the n_estimators parameter of the public methods, if the n_estimators parameter is None.\n",
    "\n",
    "##### Arguments:\n",
    "* **`proposed_value`** (`[int]`, *default*= `None`): The list of values for the n_estimators parameter. See Notes.\n",
    "\n",
    "##### Returns:\n",
    "The value to use for the n_estimators parameter.\n",
    "\n",
    "##### Notes:\n",
    "1. If n_estimators is None, the value assigned will be based on the model_search attribute:\n",
    "    * Grid: [10, 50, 100, 200]\n",
    "    * Randomized: random.randint(10, 200)\n",
    "    * Bayesian: (100, 500), i.e., (low, high)\n",
    "2. To pass a value for n_estimators, use the following guidelines for the parameter, based on the model_search attribute:\n",
    "    * Grid: pass [int]\n",
    "    * Randomized: int\n",
    "    * Bayesian: (low, high)\n",
    "\n",
    "#### `_calculate_best_grid_search_model(self, max_depth, min_samples_split, n_estimators, log)`\n",
    "Calculates the best Grid Search model for the Random Forest Classifier.\n",
    "\n",
    "##### Arguments:\n",
    "* **`rf`** (`[int]`): The RandomForestClassifier model.\n",
    "* **`max_depth`** (`[int]`, *default*= `None`): The max depth of the tree. See Notes.\n",
    "* **`min_samples_split`** (`[int]`, *default*= `None`): The list of values for the min_samples_split parameter.\n",
    "* **`n_estimators`** (`range`, *default*= `None`): The range of estimators to use. See Notes.\n",
    "* **`log`** (`bool`, *default*= `True`): If True, results are output to the console.\n",
    "\n",
    "##### Notes:\n",
    "1. If max_depth is None, the value used will be [None, 10, 20].\n",
    "2. If min_samples_split is None, the value used will be [2, 5, 10].\n",
    "3. If n_estimators is None, the value used will be [10, 50, 100, 200].\n",
    "\n",
    "#### `_calculate_best_randomized_search_model(self, max_depth, min_samples_split, n_estimators, log)`\n",
    "Calculates the best Randomized Search model for the Random Forest Classifier.\n",
    "\n",
    "##### Arguments:\n",
    "* **`rf`** (`[int]`): The RandomForestClassifier model.\n",
    "* **`max_depth`** (`[int]`, *default*= `None`): The max depth of the tree. See Notes.\n",
    "* **`min_samples_split`** (`[int]`, *default*= `None`): The list of values for the min_samples_split parameter.\n",
    "* **`n_estimators`** (`range`, *default*= `None`): The range of estimators to use. See Notes.\n",
    "* **`log`** (`bool`, *default*= `True`): If True, results are output to the console.\n",
    "\n",
    "##### Notes:\n",
    "1. If max_depth is None, the value used will be [None, 10, 20, 30].\n",
    "2. If min_samples_split is None, the value used will be random.randint(2, 11).\n",
    "3. If n_estimators is None, the value used will be random.randint(10, 200).\n",
    "\n",
    "#### `_calculate_best_bayesian_optimization_model(self, max_depth, min_samples_split, n_estimators, log)`\n",
    "Calculates the best Bayesian Optimization model for the Random Forest Classifier.\n",
    "\n",
    "##### Arguments:\n",
    "* **`max_depth`** (`[int]`, *default*= `None`): The max depth of the tree. See Notes.\n",
    "* **`min_samples_split`** (`[int]`, *default*= `None`): The list of values for the min_samples_split parameter.\n",
    "* **`n_estimators`** (`range`, *default*= `None`): The range of estimators to use. See Notes.\n",
    "* **`log`** (`bool`, *default*= `True`): If True, results are output to the console.\n",
    "\n",
    "##### Notes:\n",
    "1. If max_depth is None, the value used will be trial.suggest_int('max_depth', 5, 50).\n",
    "2. If min_samples_split is None, the value used will be trial.suggest_int('min_samples_split', 2, 10).\n",
    "3. If n_estimators is None, the value used will be trial.suggest_int('n_estimators', 10, 200).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLRandomForest:\n",
    "    def __init__(self,\n",
    "                 ml_modelsets,\n",
    "                 model_search,\n",
    "                ):\n",
    "        self._ml_modelsets = ml_modelsets\n",
    "        self._model_search = model_search\n",
    "        self._accuracy_results = MLModelResult(MLModelMethod.Accuracy)\n",
    "        self._rmse_results = MLModelResult(MLModelMethod.RMSE)\n",
    "\n",
    "    @property\n",
    "    def accuracy_results(self):\n",
    "        return self._accuracy_results\n",
    "\n",
    "    @property\n",
    "    def rmse_results(self):\n",
    "        return self._rmse_results\n",
    "    \n",
    "    def _calculate_max_depth(\n",
    "            self,\n",
    "            proposed_value=None\n",
    "    ):\n",
    "        if proposed_value is None:\n",
    "            match self._model_search:\n",
    "                case MLModelSearch.Grid:\n",
    "                    max_depth = [None, 10, 20]\n",
    "                case MLModelSearch.Randomized:\n",
    "                    max_depth = [None, 10, 20, 30]\n",
    "                case MLModelSearch.BayesianOptimization:\n",
    "                    max_depth = (2, 20)\n",
    "        else:\n",
    "            max_depth = proposed_value\n",
    "\n",
    "        return max_depth\n",
    "    \n",
    "    def _calculate_min_samples_split(\n",
    "            self,\n",
    "            proposed_value=None\n",
    "    ):\n",
    "        if proposed_value is None:\n",
    "            match self._model_search:\n",
    "                case MLModelSearch.Grid:\n",
    "                    min_samples_split = [2, 5, 10]\n",
    "                case MLModelSearch.Randomized:\n",
    "                    min_samples_split = [random.randint(2, 11)]\n",
    "                case MLModelSearch.BayesianOptimization:\n",
    "                    min_samples_split = (1e-5, 1e-2)\n",
    "        else:\n",
    "            min_samples_split = proposed_value\n",
    "\n",
    "        return min_samples_split\n",
    "    \n",
    "    def _calculate_n_estimators(\n",
    "            self,\n",
    "            proposed_value=None\n",
    "    ):\n",
    "        if proposed_value is None:\n",
    "            match self._model_search:\n",
    "                case MLModelSearch.Grid:\n",
    "                    n_estimators = [10, 50, 100, 200]\n",
    "                case MLModelSearch.Randomized:\n",
    "                    n_estimators = [random.randint(10, 200)]\n",
    "                case MLModelSearch.BayesianOptimization:\n",
    "                    n_estimators = (100, 500)\n",
    "        else:\n",
    "            n_estimators = proposed_value\n",
    "\n",
    "        return n_estimators\n",
    "\n",
    "    def calculate_best_model(self,\n",
    "                             n_estimators=None,\n",
    "                             max_depth=None,\n",
    "                             min_samples_split=None,\n",
    "                             log=True\n",
    "                            ):\n",
    "        self._accuracy_results.reset()\n",
    "        rf = RandomForestClassifier()\n",
    "\n",
    "        match self._model_search:\n",
    "            case MLModelSearch.Grid:\n",
    "                if log:\n",
    "                    print()\n",
    "                    print(f'------------ Random Forest (Accuracy): Grid ------------------')\n",
    "    \n",
    "                self._calculate_best_grid_search_model(\n",
    "                    rf,\n",
    "                    max_depth,\n",
    "                    min_samples_split,\n",
    "                    n_estimators,\n",
    "                    log\n",
    "                    )\n",
    "            case MLModelSearch.Randomized:\n",
    "                if log:\n",
    "                    print()\n",
    "                    print(f'--------- Random Forest (Accuracy): Randomized ---------------')\n",
    "    \n",
    "                self._calculate_best_randomized_search_model(\n",
    "                    rf,\n",
    "                    max_depth,\n",
    "                    min_samples_split,\n",
    "                    n_estimators,\n",
    "                    log\n",
    "                    )\n",
    "            case MLModelSearch.BayesianOptimization:\n",
    "                if log:\n",
    "                    print()\n",
    "                    print(f'---- Random Forest (Accuracy): Bayesian Optimization ----------')\n",
    "\n",
    "                self._calculate_best_bayesian_optimization_model(\n",
    "                    rf,\n",
    "                    max_depth,\n",
    "                    min_samples_split,\n",
    "                    n_estimators,\n",
    "                    log\n",
    "                    )\n",
    "\n",
    "    def _calculate_best_grid_search_model(\n",
    "            self,\n",
    "            rf,\n",
    "            max_depth=None,\n",
    "            min_samples_split=None,\n",
    "            n_estimators=None,log=True\n",
    "            ):\n",
    "        max_depth = self._calculate_max_depth(max_depth)\n",
    "        min_samples_split = self._calculate_min_samples_split(min_samples_split)\n",
    "        n_estimators = self._calculate_n_estimators(n_estimators)\n",
    "\n",
    "        param_grid = {\n",
    "            'n_estimators': n_estimators,\n",
    "            'max_depth': max_depth,\n",
    "            'min_samples_split': min_samples_split\n",
    "        }\n",
    "\n",
    "        grid_search = GridSearchCV(rf,\n",
    "                                   param_grid,\n",
    "                                   cv=5,\n",
    "                                   scoring='accuracy',\n",
    "                                   n_jobs=-1\n",
    "                                   )\n",
    "        grid_search.fit(self._ml_modelsets.df_train.features, self._ml_modelsets.df_train.target)\n",
    "        self._accuracy_results.store_result(rf, grid_search.best_score_, grid_search.best_params_)\n",
    "\n",
    "        if log:\n",
    "            print()\n",
    "            print(f'Best parameters: {grid_search.best_params_}')\n",
    "            print(f'Best score: {grid_search.best_score_}')\n",
    "\n",
    "    def _calculate_best_randomized_search_model(\n",
    "            self,\n",
    "            rf,\n",
    "            max_depth=None,\n",
    "            min_samples_split=None,\n",
    "            n_estimators=None,log=True\n",
    "            ):\n",
    "        max_depth = self._calculate_max_depth(max_depth)\n",
    "        min_samples_split = self._calculate_min_samples_split(min_samples_split)\n",
    "        n_estimators = self._calculate_n_estimators(n_estimators)\n",
    "\n",
    "        param_dist = {\n",
    "            'n_estimators': n_estimators,\n",
    "            'max_depth': max_depth,\n",
    "            'min_samples_split': min_samples_split\n",
    "        }\n",
    "\n",
    "        grid_search = GridSearchCV(rf,\n",
    "                                   param_dist,\n",
    "                                   cv=5,\n",
    "                                   scoring='accuracy',\n",
    "                                   n_jobs=-1\n",
    "                                   )\n",
    "        grid_search.fit(self._ml_modelsets.df_train.features, self._ml_modelsets.df_train.target)\n",
    "        self._accuracy_results.store_result(rf, grid_search.best_score_, grid_search.best_params_)\n",
    "\n",
    "        if log:\n",
    "            print()\n",
    "            print(f'Best parameters: {grid_search.best_params_}')\n",
    "            print(f'Best score: {grid_search.best_score_}')\n",
    "\n",
    "    def _calculate_best_bayesian_optimization_model(\n",
    "            self,\n",
    "            rf,\n",
    "            max_depth=None,\n",
    "            min_samples_split=None,\n",
    "            n_estimators=None,\n",
    "            log=True\n",
    "            ):\n",
    "        max_depth = self._calculate_max_depth(max_depth)\n",
    "        min_samples_split = self._calculate_min_samples_split(min_samples_split)\n",
    "        n_estimators = self._calculate_n_estimators(n_estimators)\n",
    "        rf_space = [\n",
    "            Integer(low=max_depth[0], high=max_depth[1], name='max_depth'),\n",
    "            Real(low=min_samples_split[0], high=min_samples_split[1], name='min_samples_split'),\n",
    "            Integer(low=n_estimators[0], high=n_estimators[1], name='n_estimators')\n",
    "        ]\n",
    "\n",
    "        @use_named_args(rf_space)\n",
    "        def objective(**params):\n",
    "            model = RandomForestClassifier(\n",
    "                random_state=self._ml_modelsets.random_state,\n",
    "                **params\n",
    "            )\n",
    "\n",
    "            score = cross_val_score(\n",
    "                model,\n",
    "                self._ml_modelsets.df_train.features,\n",
    "                self._ml_modelsets.df_train.target,\n",
    "                cv=5,\n",
    "                n_jobs=-1,\n",
    "                scoring='accuracy'\n",
    "                ).mean()\n",
    "            \n",
    "            return -score\n",
    "\n",
    "        res_gp = gp_minimize(\n",
    "            func=objective,\n",
    "            dimensions=rf_space,\n",
    "            n_calls=50,\n",
    "            n_random_starts=10,\n",
    "            random_state=self._ml_modelsets.random_state\n",
    "        )\n",
    "\n",
    "        best_hyperparameters = dict(zip([d.name for d in rf_space], res_gp.x))\n",
    "        best_score = -res_gp.fun\n",
    "        self._accuracy_results.store_result(rf, best_score, best_hyperparameters)\n",
    "\n",
    "        if log:\n",
    "            print()\n",
    "            print(f'Best cross-validation accuracy found: {best_score:.4f}')\n",
    "            print(f'Best hyperparameters: {best_hyperparameters}')\n",
    "\n",
    "    def rmse(self,\n",
    "             max_depth=None,\n",
    "             n_estimators=None,\n",
    "             log=True\n",
    "            ):\n",
    "        self._rmse_results.reset()\n",
    "        max_depth = self._calculate_max_depth(max_depth)\n",
    "        n_estimators = self._calculate_n_estimators(n_estimators)\n",
    "        \n",
    "        if log:\n",
    "            print()\n",
    "            print(f'------------------- Random Forest (RMSE) -------------------')\n",
    "\n",
    "        for est in n_estimators:\n",
    "            for depth in max_depth:\n",
    "                model = RandomForestClassifier(random_state=self._ml_modelsets.random_state,                                          \n",
    "                                               n_estimators=est,\n",
    "                                               max_depth=depth\n",
    "                                              )\n",
    "                model.fit(self._ml_modelsets.df_main.features, self._ml_modelsets.df_main.target)\n",
    "                predictions = model.predict(self._ml_modelsets.df_test.features)\n",
    "                result = mean_squared_error(self._ml_modelsets.df_test.target, predictions) ** 0.5\n",
    "                self._rmse_results.store_result(model, result, (est, depth), storage_paradigm=MLModelStorageParadigm.LowestValue)\n",
    "\n",
    "                if log:\n",
    "                    print(f'RMSE model (n_estimators, max_depth = {self._rmse_results.parameters}): {self._rmse_results.score}')        \n",
    "\n",
    "        if log:\n",
    "            print()\n",
    "            print(f'Best model: (n_estimators, max_depth = {self._rmse_results.parameters}): {self._rmse_results.score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLLogisticRegression\n",
    "\n",
    "### Summary\n",
    "Represents a Logistic Regression.\n",
    "\n",
    "### Attributes:\n",
    "* **`ml_modelsets`** (`MLModelSets`): The associated model sets object. Internal.\n",
    "* **`model`** (`LogisticRegression`): The model corresponding to the scores. Read-only.\n",
    "* **`test_score`** (`float`): The test set score. Read-only.  \n",
    "* **`train_score`** (`float`): The training set score. Read-only.\n",
    "* **`valid_score`** (`float`): The validation set score. Read-only.\n",
    "\n",
    "#### Constructor (`__init__`)\n",
    "Initializer.\n",
    "\n",
    "##### Arguments:\n",
    "* **`ml_modelsets`** (`MLModelSets`): The associated model sets object.  \n",
    "\n",
    "### Public Methods:\n",
    "\n",
    "#### `calculate_scores(self, log)`\n",
    "Calculates the scores of the various sets.\n",
    "\n",
    "##### Arguments:\n",
    "* **`log`** (`bool`, *default*= `True`): If True, results are output to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLLogisticRegression:\n",
    "    def __init__(self,\n",
    "                 ml_modelsets,\n",
    "                ):\n",
    "        self._ml_modelsets = ml_modelsets\n",
    "        self._model = None\n",
    "        self._train_score = 0.0\n",
    "        self._valid_score = 0.0\n",
    "        self._test_score = 0.0\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "        \n",
    "    @property\n",
    "    def train_score(self):\n",
    "        return self._train_score\n",
    "\n",
    "    @property\n",
    "    def valid_score(self):\n",
    "        return self._valid_score\n",
    "\n",
    "    @property\n",
    "    def test_score(self):\n",
    "        return self._test_score\n",
    "\n",
    "    def calculate_scores(self,\n",
    "                         log=True\n",
    "                        ):\n",
    "        self._model = LogisticRegression(random_state=self._ml_modelsets.random_state,\n",
    "                                         solver='liblinear'\n",
    "                                        )\n",
    "        self._model.fit(self._ml_modelsets.df_train.features, self._ml_modelsets.df_train.target)\n",
    "        self._train_score = self._model.score(self._ml_modelsets.df_train.features, self._ml_modelsets.df_train.target)\n",
    "        self._valid_score = self._model.score(self._ml_modelsets.df_valid.features, self._ml_modelsets.df_valid.target)\n",
    "        self._test_score = self._model.score(self._ml_modelsets.df_test.features, self._ml_modelsets.df_test.target)\n",
    "\n",
    "        if log:\n",
    "            print()\n",
    "            print(f'--------------- Logistic Regression (Accuracy) ---------------')\n",
    "            print(f'Accuracy of the logistic regression model on the training set: {self._train_score}')\n",
    "            print(f'Accuracy of the logistic regression model on the validation set: {self._valid_score}')\n",
    "            print(f'Accuracy of the logistic regression model on the test set: {self._test_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLLinearRegression\n",
    "\n",
    "### Summary\n",
    "Represents a Linear Regression.\n",
    "\n",
    "### Attributes:\n",
    "* **`ml_modelsets`** (`MLModelSets`): The associated model sets object. Internal.\n",
    "* **`model`** (`LinearRegression`): The model corresponding to the RMSE. Read-only.\n",
    "* **`rmse_result`** (`float`): The calculated RMSE. Read-only.  \n",
    "\n",
    "#### Constructor (`__init__`)\n",
    "Initializer.\n",
    "\n",
    "##### Arguments:\n",
    "* **`ml_modelsets`** (`MLModelSets`): The associated model sets object.  \n",
    "\n",
    "### Public Methods:\n",
    "\n",
    "#### `rmse(self, log)`\n",
    "Calculates the RMSE, and updates the object properties.\n",
    "\n",
    "##### Arguments:\n",
    "* **`log`** (`bool`, *default*= `True`): If True, results are output to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLLinearRegression:\n",
    "    def __init__(self,\n",
    "                 ml_modelsets,\n",
    "                ):\n",
    "        self._ml_modelsets = ml_modelsets\n",
    "        self._model = None\n",
    "        self._rmse_result = 0.0\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "        \n",
    "    @property\n",
    "    def rmse_result(self):\n",
    "        return self._rmse_result\n",
    "\n",
    "    def rmse(self,\n",
    "             log=True\n",
    "            ):\n",
    "        model = LinearRegression()\n",
    "        model.fit(self._ml_modelsets.df_main.features, self._ml_modelsets.df_main.target)\n",
    "        predictions = model.predict(self._ml_modelsets.df_test.features)\n",
    "        self._rmse_result = mean_squared_error(self._ml_modelsets.df_test.target, predictions) ** 0.5\n",
    "\n",
    "        if log:\n",
    "            print()\n",
    "            print(f'----------------- Linear Regression (RMSE) -----------------')\n",
    "            print(f'Linear Regression: {self._rmse_result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLThreeSetSplit\n",
    "\n",
    "### Summary\n",
    "Creates machine learning datasets from a source dataset. Includes methods to determine the best model, and to provide a summary of the model calculations.\n",
    "\n",
    "### Attributes:\n",
    "* **`accuracy_threshold`** (`float`): The lowest accuracy value that should be considered for a final model. Read-write.\n",
    "* **`best_model`** (`MLModel`): The model type that produces the most accurate model. Internal.\n",
    "* **`best_score`** (`float`): The best model classifier score. Internal.\n",
    "* **`decision_tree`** (`MLDecisionTree`): The Decision Tree Classifier. Internal.\n",
    "* **`df`** (`dataset`): The dataframe object. Internal.\n",
    "* **`df_main`** (`dataset`): The main dataset, created by the initial train_test_split. Read-only.\n",
    "* **`df_target`** (`dataset`): The target from the complete source dataset. Read-only.\n",
    "* **`df_test`** (`dataset`): The test dataset, created by the initial train_test_split. Read-only.\n",
    "* **`df_train`** (`dataset`): The training dataset. Read-only.\n",
    "* **`df_valid`** (`dataset`): The validation dataset. Read-only.\n",
    "* **`features_to_ignore`** (`[str]`): A list of columns (other than target) to ignore for training. Internal.\n",
    "* **`linear_regression`** (`MLLinearRegression`): The Linear Regression. Internal.\n",
    "* **`logistic_regression`** (`MLLogisticRegression`): The Logistic Regression. Internal.\n",
    "* **`random_forest_bayesian_optimization`** (`MLRandomForest`): The Random Forest Classifier for use with a Bayesian Optimization. Internal.\n",
    "* **`random_forest_grid`** (`MLRandomForest`): The Random Forest Classifier for use with a Grid Search. Internal.\n",
    "* **`random_forest_randomized`** (`MLRandomForest`): The Random Forest Classifier for use with a Randomized Search. Internal.\n",
    "* **`random_state`** (`int`): The random state to use. Internal.\n",
    "* **`target`** (`[str]`): A list of columns to use as target. Internal.\n",
    "* **`test_size`** (`float`): The portion of the source dataset to use for testing. Internal.\n",
    "* **`valid_size`** (`float`): The portion of the main dataset to use for validation. Internal.\n",
    "\n",
    "#### Constructor (`__init__`)\n",
    "Initializer.\n",
    "\n",
    "##### Arguments:\n",
    "* **`df`** (`dataset`): The dataframe object.\n",
    "* **`target`** (`[str]`): A list of columns to use as target.\n",
    "* **`features_to_ignore`** (`[str]`, *default*= `[]`): A list of columns (other than target) to ignore for training.\n",
    "* **`test_size`** (`float`, *default*= `0.2`): The portion of the source dataset to use for testing. See Notes.\n",
    "* **`valid_size`** (`float`, *default*= `0.25`): The portion of the main dataset to use for validation. See Notes.\n",
    "* **`random_state`** (`int`, *default*= `12345`): The random state to use.\n",
    "* **`accuracy_threshold`** (`float`, *default*= `0.0`): The lowest accuracy value that should be considered for a final model.\n",
    "\n",
    "##### Notes:\n",
    "1. The main (working) dataset is the result of the split between the source dataset and the test dataset. If the ratio for train:validation:test is to be 3:1:1, specify 0.2 for the test set, and 0.25 for the validation set (25% of 80% = 20% of the source dataset). These are the default values for the \\_\\_init\\_\\_ method.\n",
    "\n",
    "### Public Methods:\n",
    "\n",
    "#### `train_test_split(self)`\n",
    "* Initializes the following attributes:\n",
    "    * df_main\n",
    "    * df_test\n",
    "    * df_train\n",
    "    * df_valid\n",
    "    * decision_tree\n",
    "    * random_forest_grid\n",
    "    * random_forest_randomized\n",
    "    * random_forest_bayesian_optimization\n",
    "    * logistic_regression\n",
    "    * linear_regression\n",
    "\n",
    "#### `analyze_models(self, max_depth, min_samples_split, estimators, log)`\n",
    "\n",
    "Investigates the quality of the various models (Decision Tree, Random Forest, Logistic Regression), and determines the best model based on the accuracy threshold.\n",
    "\n",
    "##### Arguments:\n",
    "* **`max_depth`** (`[int]`, *default*= `None`): The max depth of the tree.  See Notes.\n",
    "* **`min_samples_split`** (`[int]`, *default*= `None`): The list of values for the min_samples_split parameter. See Notes.\n",
    "* **`n_estimators`** (`range`, *default*= `None`): The range of estimators to use. See Notes.\n",
    "* **`log`** (`bool`, *default*= `True`): If True, results are output to the console.\n",
    "\n",
    "##### Notes:\n",
    "1. If max_depth is None, the value assigned will be based on the model_search attribute:\n",
    "    * Grid: [None, 10, 20]\n",
    "    * Randomized: [None, 10, 20, 30]\n",
    "    * Bayesian: (2, 20), i.e., (low, high)\n",
    "2. To pass a value for max_depth, use the following guidelines for the parameter, based on the model_search attribute:\n",
    "    * Grid: pass [int]\n",
    "    * Randomized: int\n",
    "    * Bayesian: (low, high)\n",
    "3. If min_samples_split is None, the value assigned will be based on the model_search attribute:\n",
    "    * Grid: [2, 5, 10]\n",
    "    * Randomized: random.randint(2, 11)\n",
    "    * Bayesian: (1e-5, 1e-2), i.e., (low, high)\n",
    "4. To pass a value for min_samples_split, use the following guidelines for the parameter, based on the model_search attribute:\n",
    "    * Grid: pass [int]\n",
    "    * Randomized: int\n",
    "    * Bayesian: (low, high)\n",
    "5. If n_estimators is None, the value assigned will be based on the model_search attribute:\n",
    "    * Grid: [10, 50, 100, 200]\n",
    "    * Randomized: random.randint(10, 200)\n",
    "    * Bayesian: (100, 500), i.e., (low, high)\n",
    "6. To pass a value for n_estimators, use the following guidelines for the parameter, based on the model_search attribute:\n",
    "    * Grid: pass [int]\n",
    "    * Randomized: int\n",
    "    * Bayesian: (low, high)\n",
    "\n",
    "#### `model_summary(self)`\n",
    "Returns a summary of the model analysis.\n",
    "\n",
    "* **Returns:**\n",
    "    * `str` The summary of the model analysis.\n",
    "\n",
    "Sample output:\n",
    "```python\n",
    "------------------ Model Summary ------------------\n",
    "Best model within accuracy threshold: Random Forest (Grid)\n",
    "\n",
    "parameters: {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100}\n",
    "accuracy:   82.00%\n",
    "```\n",
    "\n",
    "#### `sanity_check(self, depths, estimators, log)`\n",
    "Calls the rmse() function for each model type, and, optionally, prints the results.\n",
    "\n",
    "##### Arguments:\n",
    "* **`max_depth`** (`range`, *default*= `None`): The range of values to use with Decision Tree and Random Forest models. See Notes.\n",
    "* **`n_estimators`** (`range`, *default*= `None`): The range of values to use as estimators with Random Forest models. See Notes.\n",
    "* **`log`** (`bool`, *default*= `True`): If True, results are output to the console.\n",
    "\n",
    "##### Notes:\n",
    "1. If max_depth is None, the value assigned will be based on the model_search attribute:\n",
    "    * Grid: [None, 10, 20]\n",
    "    * Randomized: [None, 10, 20, 30]\n",
    "    * Bayesian: (2, 20), i.e., (low, high)\n",
    "2. To pass a value for max_depth, use the following guidelines for the parameter, based on the model_search attribute:\n",
    "    * Grid: pass [int]\n",
    "    * Randomized: int\n",
    "    * Bayesian: (low, high)\n",
    "3. If n_estimators is None, the value assigned will be based on the model_search attribute:\n",
    "    * Grid: [10, 50, 100, 200]\n",
    "    * Randomized: random.randint(10, 200)\n",
    "    * Bayesian: (100, 500), i.e., (low, high)\n",
    "4. To pass a value for n_estimators, use the following guidelines for the parameter, based on the model_search attribute:\n",
    "    * Grid: pass [int]\n",
    "    * Randomized: int\n",
    "    * Bayesian: (low, high)\n",
    "\n",
    "### Private Methods:\n",
    "\n",
    "#### `evaluate_models(self)`\n",
    "Evaluates the models, to determine which is the best model for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLThreeSetSplit(MLModelSets):\n",
    "    def __init__(self, \n",
    "                 df, \n",
    "                 target, \n",
    "                 features_to_ignore=[], \n",
    "                 test_size=0.2, \n",
    "                 valid_size=0.25,\n",
    "                 random_state=12345,\n",
    "                 accuracy_threshold=0.0\n",
    "                ):\n",
    "        self._df = df\n",
    "        self._target = any_to_list(target)\n",
    "        self._features_to_ignore = any_to_list(features_to_ignore)\n",
    "        self._test_size = test_size\n",
    "        self._valid_size = valid_size\n",
    "        self._random_state = random_state\n",
    "        self._accuracy_threshold = accuracy_threshold\n",
    "        self._df_target = df[self._target]\n",
    "        self._df_main = None\n",
    "        self._df_test = None\n",
    "        self._df_train = None\n",
    "        self._df_valid = None\n",
    "        self._best_model = MLModel.Undefined\n",
    "        self._best_score = 0.0\n",
    "        self._decision_tree = None\n",
    "        self._random_forest_grid = None\n",
    "        self._random_forest_randomized = None\n",
    "        self._random_forest_bayesian_optimization = None\n",
    "        self._logistic_regression = None\n",
    "        self._linear_regression = None\n",
    "\n",
    "    @property\n",
    "    def df_target(self):\n",
    "        return self._df_target\n",
    "\n",
    "    @property\n",
    "    def df_main(self):\n",
    "        return self._df_main\n",
    "\n",
    "    @property\n",
    "    def df_test(self):\n",
    "        return self._df_test\n",
    "\n",
    "    @property\n",
    "    def df_train(self):\n",
    "        return self._df_train\n",
    "\n",
    "    @property\n",
    "    def df_valid(self):\n",
    "        return self._df_valid\n",
    "\n",
    "    @property\n",
    "    def random_state(self):\n",
    "        return self._random_state\n",
    "\n",
    "    @property\n",
    "    def accuracy_threshold(self):\n",
    "        return\n",
    "\n",
    "    @accuracy_threshold.setter\n",
    "    def accuracy_threshold(self, value):\n",
    "        self._accuracy_threshold = float(value)\n",
    "\n",
    "    def train_test_split(self):\n",
    "        if len(self._features_to_ignore) > 0:\n",
    "            tts_features = self._df.drop(self._features_to_ignore, axis=1)\n",
    "        else:\n",
    "            tts_features = self._df\n",
    "        \n",
    "        tts_features = tts_features.drop(self._target, axis=1)\n",
    "        tts_target = self._df[self._target]\n",
    "\n",
    "        # Create main (for training and validation) and test sets\n",
    "        features_main, features_test, target_main, target_test = train_test_split(tts_features, \n",
    "                                                                                  tts_target,\n",
    "                                                                                  test_size=self._test_size, \n",
    "                                                                                  random_state=self._random_state\n",
    "                                                                                 )\n",
    "        self._df_main = MLDataset(features_main,\n",
    "                                  target_main\n",
    "                                  )\n",
    "        self._df_test = MLDataset(features_test,\n",
    "                                  target_test\n",
    "                                 )\n",
    "\n",
    "        # Create training and validation sets\n",
    "        features_train, features_valid, target_train, target_valid = train_test_split(features_main, \n",
    "                                                                                      target_main,\n",
    "                                                                                      test_size=self._valid_size, \n",
    "                                                                                      random_state=self._random_state\n",
    "                                                                                     )\n",
    "        self._df_train = MLDataset(features_train,\n",
    "                                   target_train\n",
    "                                  )\n",
    "        self._df_valid = MLDataset(features_valid,\n",
    "                                   target_valid\n",
    "                                  )\n",
    "\n",
    "        self._decision_tree = MLDecisionTree(self)\n",
    "        self._random_forest_grid = MLRandomForest(self, MLModelSearch.Grid)\n",
    "        self._random_forest_randomized = MLRandomForest(self, MLModelSearch.Randomized)\n",
    "        self._random_forest_bayesian_optimization = MLRandomForest(self, MLModelSearch.BayesianOptimization)\n",
    "        self._logistic_regression = MLLogisticRegression(self)\n",
    "        self._linear_regression = MLLinearRegression(self)\n",
    "\n",
    "    def analyze_models(\n",
    "            self,\n",
    "            max_depth=None,\n",
    "            min_samples_split=None,\n",
    "            n_estimators=None,\n",
    "            log=True\n",
    "            ):\n",
    "        self.train_test_split()\n",
    "        self._decision_tree.tune(\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            log=log\n",
    "            )\n",
    "        self._random_forest_grid.calculate_best_model(\n",
    "            n_estimators=n_estimators,\n",
    "            log=log\n",
    "            )\n",
    "        self._random_forest_randomized.calculate_best_model(\n",
    "            n_estimators=n_estimators,\n",
    "            log=log\n",
    "            )\n",
    "        self._random_forest_bayesian_optimization.calculate_best_model(\n",
    "            n_estimators=n_estimators,\n",
    "            log=log\n",
    "            )\n",
    "        self._logistic_regression.calculate_scores(log=log)\n",
    "\n",
    "    def _evaluate_models(self):\n",
    "        # Models in order of Accuracy: DecisionTree (low), LogisticRegression (medium), RandomForest (high)\n",
    "        self._best_score = 0.0\n",
    "        self._best_model = None\n",
    "\n",
    "        if self._decision_tree.accuracy_results.score >= self._accuracy_threshold:\n",
    "            self._best_model = MLModel.DecisionTree\n",
    "            self._best_score = self._decision_tree.accuracy_results.score\n",
    "\n",
    "        if self._logistic_regression.test_score >= self._accuracy_threshold and \\\n",
    "            self._logistic_regression.test_score > self._best_score:\n",
    "            self._best_model = MLModel.LogisticRegression\n",
    "            self._best_score = self._logistic_regression.test_score\n",
    "\n",
    "        if self._random_forest_grid.accuracy_results.score >= self._accuracy_threshold and \\\n",
    "            self._random_forest_grid.accuracy_results.score > self._best_score:\n",
    "            self._best_model = MLModel.RandomForestGrid\n",
    "            self._best_score = self._random_forest_grid.accuracy_results.score\n",
    "\n",
    "        if self._random_forest_randomized.accuracy_results.score >= self._accuracy_threshold and \\\n",
    "            self._random_forest_randomized.accuracy_results.score > self._best_score:\n",
    "            self._best_model = MLModel.RandomForestRandomized\n",
    "            self._best_score = self._random_forest_randomized.accuracy_results.score\n",
    "\n",
    "        if self._random_forest_bayesian_optimization.accuracy_results.score >= self._accuracy_threshold and \\\n",
    "            self._random_forest_bayesian_optimization.accuracy_results.score > self._best_score:\n",
    "            self._best_model = MLModel.RandomForestBayesianOptimization\n",
    "            self._best_score = self._random_forest_bayesian_optimization.accuracy_results.score\n",
    "\n",
    "    def model_summary(self):\n",
    "        self._evaluate_models()\n",
    "        best_model = \"Unable to determine best model\"\n",
    "        model_description = \"\"\n",
    "        \n",
    "        if self._best_model == MLModel.Undefined:\n",
    "            best_model = \"Undefined\"\n",
    "        elif self._best_model == MLModel.DecisionTree:\n",
    "            best_model = \"Decision Tree\"\n",
    "            model_description = f\"\"\"\n",
    "max_depth: {self._decision_tree.accuracy_results.depth}\n",
    "accuracy:  {self._decision_tree.accuracy_results.score:.2%}\n",
    "\"\"\"\n",
    "        elif self._best_model == MLModel.RandomForestGrid:\n",
    "            best_model = \"Random Forest (Grid)\"\n",
    "            model_description = f\"\"\"\n",
    "parameters: {self._random_forest_grid.accuracy_results.parameters}\n",
    "accuracy:   {self._random_forest_grid.accuracy_results.score:.2%}\n",
    "\"\"\"            \n",
    "        elif self._best_model == MLModel.RandomForestRandomized:\n",
    "            best_model = \"Random Forest (Randomized)\"\n",
    "            model_description = f\"\"\"\n",
    "parameters: {self._random_forest_randomized.accuracy_results.parameters}\n",
    "accuracy:   {self._random_forest_randomized.accuracy_results.score:.2%}\n",
    "\"\"\"            \n",
    "        elif self._best_model == MLModel.RandomForestBayesianOptimization:\n",
    "            best_model = \"Random Forest (Bayesian Optimization)\"\n",
    "            model_description = f\"\"\"\n",
    "parameters: {self._random_forest_bayesian_optimization.accuracy_results.parameters}\n",
    "accuracy:   {self._random_forest_bayesian_optimization.accuracy_results.score:.2%}\n",
    "\"\"\"            \n",
    "        elif self._best_model == MLModel.LogisticRegression:\n",
    "            best_model = \"Logistic Regression\"\n",
    "            model_description = f\"\"\"\n",
    "accuracy:   {self._logistic_regression.test_score:.2%}\n",
    "\"\"\"     \n",
    "        else:\n",
    "            best_model = \"Unknown value\"\n",
    "\n",
    "        summary = f\"\"\"------------------ Model Summary ------------------\n",
    "Best model within accuracy threshold: {best_model}\n",
    "{model_description}\n",
    "\"\"\"\n",
    "        return summary\n",
    "\n",
    "    def sanity_check(self,\n",
    "                     max_depth=None,\n",
    "                     n_estimators=None,\n",
    "                     log=True\n",
    "                    ):\n",
    "        self._decision_tree.rmse(max_depth=max_depth,\n",
    "                                 log=log\n",
    "                                )\n",
    "        self._random_forest_grid.rmse(max_depth=max_depth,\n",
    "                                 n_estimators=n_estimators,\n",
    "                                 log=log\n",
    "                                )\n",
    "        self._linear_regression.rmse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1&emsp;Load and Analyze the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 3214\n",
      "Duplicate rows: 0\n",
      "\n",
      "Column           Non-null   Data type   \n",
      "calls                3214   float64     \n",
      "minutes              3214   float64     \n",
      "messages             3214   float64     \n",
      "mb_used              3214   float64     \n",
      "is_ultra             3214   int64       \n",
      "\n",
      "Column:             calls\n",
      "Data type:          float64\n",
      "Non-null:           3214\n",
      "N/A count:          0\n",
      "Unique values:      184\n",
      "Integer values:     3214\n",
      "Non-integer values: 0\n",
      "\n",
      "\n",
      "Column:             minutes\n",
      "Data type:          float64\n",
      "Non-null:           3214\n",
      "N/A count:          0\n",
      "Unique values:      3149\n",
      "Integer values:     57\n",
      "Non-integer values: 3157\n",
      "\n",
      "\n",
      "Column:             messages\n",
      "Data type:          float64\n",
      "Non-null:           3214\n",
      "N/A count:          0\n",
      "Unique values:      180\n",
      "Integer values:     3214\n",
      "Non-integer values: 0\n",
      "\n",
      "\n",
      "Column:             mb_used\n",
      "Data type:          float64\n",
      "Non-null:           3214\n",
      "N/A count:          0\n",
      "Unique values:      3203\n",
      "Integer values:     26\n",
      "Non-integer values: 3188\n",
      "\n",
      "\n",
      "Column:             is_ultra\n",
      "Data type:          int64\n",
      "Non-null:           3214\n",
      "N/A count:          0\n",
      "Unique values:      2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.DataframeInfo at 0x16d1027b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_behavior = pd.read_csv('datasets/users_behavior.csv')\n",
    "analyze_dataset(users_behavior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1&emsp;Data Analysis Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3214 records in the dataset.  \n",
    "The data types of the columns are shown above.  \n",
    "There are no missing values in any of the columns.  \n",
    "Importing the csv file into Excel allowed for further data inspection.  \n",
    "\n",
    "* Issues / Patterns / Anomalies\n",
    "    * calls\n",
    "        * This column has zero non-integer values.\n",
    "        * Convert to int64.\n",
    "    * minutes\n",
    "        * The Excel import reveals that many values in this column have significantly more than two decimal places.\n",
    "        * For this analysis, fractional minutes are not significant.\n",
    "        * Convert the values to int64, effectively rounding down to zero decimal places.\n",
    "    * messages\n",
    "        * This column has zero non-integer values.\n",
    "        * Convert to int64.\n",
    "    * mb_used\n",
    "        * The Excel import reveals that many values in this column have significantly more than two decimal places.\n",
    "        * For this analysis, fractional mb of data are not significant.\n",
    "        * Convert the values to int64, effectively rounding down to zero decimal places.\n",
    "    * is_ultra\n",
    "        * This column has two unique values.\n",
    "        * The values must remain numeric in order to use the column as a target in RMSE calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2&emsp;Data Preparation\n",
    "\n",
    "### Manipulate the dataset based on the conclusions reached in the Data Analysis Summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   calls     3214 non-null   int64\n",
      " 1   minutes   3214 non-null   int64\n",
      " 2   messages  3214 non-null   int64\n",
      " 3   mb_used   3214 non-null   int64\n",
      " 4   is_ultra  3214 non-null   int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 125.7 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>311</td>\n",
       "      <td>83</td>\n",
       "      <td>19915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>516</td>\n",
       "      <td>56</td>\n",
       "      <td>22696</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>467</td>\n",
       "      <td>86</td>\n",
       "      <td>21060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106</td>\n",
       "      <td>745</td>\n",
       "      <td>81</td>\n",
       "      <td>8437</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>418</td>\n",
       "      <td>1</td>\n",
       "      <td>14502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages  mb_used  is_ultra\n",
       "0     40      311        83    19915         0\n",
       "1     85      516        56    22696         0\n",
       "2     77      467        86    21060         0\n",
       "3    106      745        81     8437         1\n",
       "4     66      418         1    14502         0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change data types, as needed.\n",
    "users_behavior = users_behavior.astype({'calls': 'int64', \n",
    "                                        'minutes': 'int64',\n",
    "                                        'messages': 'int64',\n",
    "                                        'mb_used': 'int64'\n",
    "                                       })\n",
    "\n",
    "# Print info() and head() for verification.\n",
    "users_behavior.info()\n",
    "users_behavior.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3&emsp;Create main set, training set, validation set, and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_source = MLThreeSetSplit(users_behavior,\n",
    "                            'is_ultra'\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1&emsp;Analyze Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------ Decision Tree (Accuracy) ------------------\n",
      "\n",
      "Best parameters: {'max_depth': 10, 'min_samples_split': 10}\n",
      "Best score: 0.7852943947244466\n",
      "\n",
      "------------ Random Forest (Accuracy): Grid ------------------\n",
      "\n",
      "Best parameters: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Best score: 0.8195007065473388\n",
      "\n",
      "--------- Random Forest (Accuracy): Randomized ---------------\n",
      "\n",
      "Best parameters: {'max_depth': 10, 'min_samples_split': 4, 'n_estimators': 190}\n",
      "Best score: 0.8137971872686898\n",
      "\n",
      "---- Random Forest (Accuracy): Bayesian Optimization ----------\n",
      "\n",
      "Best cross-validation accuracy found: 0.8180\n",
      "Best hyperparameters: {'max_depth': np.int64(7), 'min_samples_split': 0.003993452899784223, 'n_estimators': np.int64(423)}\n",
      "\n",
      "--------------- Logistic Regression (Accuracy) ---------------\n",
      "Accuracy of the logistic regression model on the training set: 0.7017634854771784\n",
      "Accuracy of the logistic regression model on the validation set: 0.6951788491446346\n",
      "Accuracy of the logistic regression model on the test set: 0.6951788491446346\n"
     ]
    }
   ],
   "source": [
    "ml_source.analyze_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Print Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Model Summary ------------------\n",
      "Best model within accuracy threshold: Random Forest (Grid)\n",
      "\n",
      "parameters: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "accuracy:   81.95%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ml_source.model_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion  \n",
    "\n",
    "* The accuracy threshold is 75%.\n",
    "* The best Decision Tree and Random Forest models were within the accuracy threshold.\n",
    "* Of these two, the Random Forest (Grid) model had the higher accuracy score (81.95%).\n",
    "* The Logistic Regression test model did not reach the accuracy threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4&emsp;Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------- Decision Tree (RMSE) -------------------\n",
      "max_depth = None : 0.5334823534681324\n",
      "max_depth = 10 : 0.48299222871755937\n",
      "max_depth = 20 : 0.5392812450616766\n",
      "\n",
      "Best model: 10 (0.48299222871755937)\n",
      "\n",
      "------------------- Random Forest (RMSE) -------------------\n",
      "RMSE model (n_estimators, max_depth = (10, None)): 0.4748741340974856\n",
      "RMSE model (n_estimators, max_depth = (10, 10)): 0.45136737131523463\n",
      "RMSE model (n_estimators, max_depth = (10, 10)): 0.45136737131523463\n",
      "RMSE model (n_estimators, max_depth = (10, 10)): 0.45136737131523463\n",
      "RMSE model (n_estimators, max_depth = (50, 10)): 0.447908566541585\n",
      "RMSE model (n_estimators, max_depth = (50, 10)): 0.447908566541585\n",
      "RMSE model (n_estimators, max_depth = (50, 10)): 0.447908566541585\n",
      "RMSE model (n_estimators, max_depth = (50, 10)): 0.447908566541585\n",
      "RMSE model (n_estimators, max_depth = (50, 10)): 0.447908566541585\n",
      "RMSE model (n_estimators, max_depth = (50, 10)): 0.447908566541585\n",
      "RMSE model (n_estimators, max_depth = (200, 10)): 0.44616910922652836\n",
      "RMSE model (n_estimators, max_depth = (200, 10)): 0.44616910922652836\n",
      "\n",
      "Best model: (n_estimators, max_depth = (200, 10)): 0.44616910922652836\n",
      "\n",
      "----------------- Linear Regression (RMSE) -----------------\n",
      "Linear Regression: 0.44319818230570085\n"
     ]
    }
   ],
   "source": [
    "ml_source.sanity_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion  \n",
    "\n",
    "* The Linear Regression model score (0.443) is the best RSME model.\n",
    "* The best Random Forest model (n_estimators = 200, depth = 10) is only 0.003 above the Linear Regression model, a virtual tie for the best RSME model.\n",
    "* The best Decision Tree model (max_depth = 10) score is only 0.036 higher.\n",
    "\n",
    "Given the success of the Random Forest model in both accuracy and RMSE, that model is determined to have the highest quality overall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
